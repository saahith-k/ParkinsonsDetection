# -*- coding: utf-8 -*-
"""ParkinsonsNew.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1q6r5Lg_76eM4xR-1R8Zii4E5sqJ40Q9A
"""

from google.colab import drive
import zipfile, os

drive.mount('/content/drive')

zip_path = "/content/drive/MyDrive/ParkinsonsDatasetNew.zip"  # change if needed
extract_path = "/content/raw_dataset"

with zipfile.ZipFile(zip_path, 'r') as zip_ref:
    zip_ref.extractall(extract_path)

print("âœ… Dataset extracted.")

import shutil
from sklearn.model_selection import train_test_split

src_healthy = os.path.join(extract_path, "Dataset", "Healthy")
src_parkinson = os.path.join(extract_path, "Dataset", "Parkinson")

# Create destination folders
base_dir = "/content/organized_dataset"
for split in ['train', 'val', 'test']:
    for cls in ['Healthy', 'Parkinson']:
        os.makedirs(os.path.join(base_dir, split, cls), exist_ok=True)

# Helper to split & copy images
def split_and_copy(src_dir, label):
    images = os.listdir(src_dir)
    train, temp = train_test_split(images, test_size=0.3, random_state=42)
    val, test = train_test_split(temp, test_size=0.5, random_state=42)

    for split, split_data in zip(['train', 'val', 'test'], [train, val, test]):
        for img in split_data:
            shutil.copy(os.path.join(src_dir, img), os.path.join(base_dir, split, label, img))

split_and_copy(src_healthy, "Healthy")
split_and_copy(src_parkinson, "Parkinson")

print("âœ… Data organized into train/val/test")

from tensorflow.keras.preprocessing.image import ImageDataGenerator

IMG_SIZE = 256
BATCH_SIZE = 32

train_gen = ImageDataGenerator(
    rescale=1./255,
    rotation_range=30,
    zoom_range=0.3,
    shear_range=0.2,
    brightness_range=[0.8, 1.2],
    horizontal_flip=True
)

val_test_gen = ImageDataGenerator(rescale=1./255)

train_data = train_gen.flow_from_directory(
    base_dir + "/train",
    target_size=(IMG_SIZE, IMG_SIZE),
    batch_size=BATCH_SIZE,
    class_mode='categorical'
)

val_data = val_test_gen.flow_from_directory(
    base_dir + "/val",
    target_size=(IMG_SIZE, IMG_SIZE),
    batch_size=BATCH_SIZE,
    class_mode='categorical'
)

test_data = val_test_gen.flow_from_directory(
    base_dir + "/test",
    target_size=(IMG_SIZE, IMG_SIZE),
    batch_size=BATCH_SIZE,
    class_mode='categorical',
    shuffle=False
)

from tensorflow.keras.applications import ResNet50
from tensorflow.keras.models import Model
from tensorflow.keras.layers import GlobalAveragePooling2D, Dropout, Dense
from tensorflow.keras.optimizers import Adam

base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(IMG_SIZE, IMG_SIZE, 3))

# âœ… Fine-tune top 30 layers
for layer in base_model.layers[:-30]:
    layer.trainable = False
for layer in base_model.layers[-30:]:
    layer.trainable = True

x = base_model.output
x = GlobalAveragePooling2D()(x)
x = Dropout(0.4)(x)
output = Dense(2, activation='softmax')(x)

model = Model(inputs=base_model.input, outputs=output)

model.compile(optimizer=Adam(learning_rate=1e-5), loss='categorical_crossentropy', metrics=['accuracy'])

model.summary()

from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau

callbacks = [
    EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True),
    ReduceLROnPlateau(monitor='val_loss', factor=0.3, patience=2)
]

history = model.fit(
    train_data,
    epochs=30,
    validation_data=val_data,
    callbacks=callbacks
)

import numpy as np
from sklearn.metrics import classification_report, confusion_matrix
import matplotlib.pyplot as plt
import seaborn as sns

# Evaluate
loss, acc = model.evaluate(test_data)
print(f"\nâœ… Final Test Accuracy: {acc*100:.2f}%")

# Predictions
pred_probs = model.predict(test_data)
y_pred = np.argmax(pred_probs, axis=1)
y_true = test_data.classes
class_labels = list(test_data.class_indices.keys())

print("\nClassification Report:")
print(classification_report(y_true, y_pred, target_names=class_labels))

cm = confusion_matrix(y_true, y_pred)
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=class_labels, yticklabels=class_labels)
plt.xlabel('Predicted')
plt.ylabel('True')
plt.title('Confusion Matrix')
plt.show()

from google.colab import files
uploaded = files.upload()

from tensorflow.keras.preprocessing import image
import numpy as np

IMG_SIZE = 256  # your training input size

# Load uploaded image
img_path = list(uploaded.keys())[0]
img = image.load_img(img_path, target_size=(IMG_SIZE, IMG_SIZE))
img_array = image.img_to_array(img)
img_array = img_array / 255.0  # same rescaling as during training
img_array = np.expand_dims(img_array, axis=0)  # make it batch size = 1

# Predict
pred = model.predict(img_array)
predicted_class = np.argmax(pred, axis=1)[0]
confidence = np.max(pred)

# Map index to class name
class_names = list(train_data.class_indices.keys())  # ['Healthy', 'Parkinson']
predicted_label = class_names[predicted_class]

print(f"ðŸ§  Predicted: {predicted_label} ({confidence * 100:.2f}% confidence)")

import matplotlib.pyplot as plt

plt.imshow(img)
plt.axis('off')
plt.title(f"Predicted: {predicted_label} ({confidence*100:.2f}%)")
plt.show()

